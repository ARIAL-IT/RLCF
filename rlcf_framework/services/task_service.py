from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from .. import models, aggregation_engine, post_processing, bias_analysis


async def orchestrate_task_aggregation(db: AsyncSession, task_id: int):
    """
    Orchestra il processo completo di aggregazione, post-processing e analisi bias per un task.

    Implementa l'alta-level business logic per complete task workflows come descritto
    in RLCF.md Sezione 4.1. Questa funzione decouples business logic dagli API endpoints
    e gestisce l'orchestrazione atomica di:
    1. Uncertainty-preserving aggregation (Algorithm 1)
    2. Consistency calculation e correctness scoring
    3. Bias analysis e reporting
    
    Each major operation manages its own transaction per garantire resilience
    a partial failures, seguendo i principi del Constitutional Governance Model.

    Args:
        db: AsyncSession for database operations
        task_id: ID of the task to orchestrate aggregation for
        
    References:
        RLCF.md Section 4.1 - Task Lifecycle Management
        RLCF.md Section 3.1 - Algorithm 1: RLCF Aggregation with Uncertainty Preservation
        RLCF.md Section 4.3 - Extended Bias Detection Framework
    """
    # 1. Aggregate and save result - atomic operation
    await _aggregate_and_save_result(db, task_id)

    # 2. Calculate and store consistency - atomic operation
    await _calculate_and_store_consistency(db, task_id)

    # 3. Calculate and store bias - atomic operation
    await _calculate_and_store_bias(db, task_id)


async def _aggregate_and_save_result(db: AsyncSession, task_id: int) -> dict:
    """
    Atomic operation to calculate and save aggregation result.
    
    Esegue l'Algorithm 1: RLCF Aggregation with Uncertainty Preservation
    per il task specificato, gestendo authority weighting, disagreement
    quantification e uncertainty preservation come definito in RLCF.md Sezione 3.1.

    Args:
        db: AsyncSession for database operations
        task_id: ID of the task to aggregate

    Returns:
        dict: Aggregation result with uncertainty information or error
        
    References:
        RLCF.md Section 3.1 - Algorithm 1: RLCF Aggregation with Uncertainty Preservation
    """
    try:
        result = await aggregation_engine.aggregate_with_uncertainty(db, task_id)
        if "error" not in result:
            # Store the aggregation result (implementation would depend on your needs)
            # For now, we just return the result
            pass
        return result
    except Exception as e:
        # Log error but don't re-raise to allow other operations to continue
        print(f"Error in aggregation for task {task_id}: {e}")
        return {"error": str(e)}


async def _calculate_and_store_consistency(db: AsyncSession, task_id: int):
    """
    Atomic operation to calculate and store consistency scores.
    
    Calcola consistency scores per ogni feedback rispetto al risultato aggregato
    e correctness scores rispetto al ground truth quando disponibile.
    Implementa le metriche di qualit√† Q_u(t) usate nel Dynamic Authority Scoring Model
    descritto in RLCF.md Sezione 2.3.

    Args:
        db: AsyncSession for database operations
        task_id: ID of the task to calculate consistency for
        
    References:
        RLCF.md Section 2.3 - Track Record Evolution Model
        RLCF.md Section 2.4 - Multi-Objective Reward Function
    """
    try:
        # Get aggregation result first
        result = await aggregation_engine.aggregate_with_uncertainty(db, task_id)
        if "error" in result:
            return

        await post_processing.calculate_and_store_consistency(db, task_id, result)
        await post_processing.calculate_and_store_correctness(db, task_id)
    except Exception as e:
        print(f"Error in consistency calculation for task {task_id}: {e}")
        await db.rollback()


async def _calculate_and_store_bias(db: AsyncSession, task_id: int):
    """
    Atomic operation to calculate and store bias reports.
    
    Implementa il 6-dimensional bias detection framework descritto in RLCF.md
    Sezione 4.3, calcolando bias scores per ogni partecipante e generando
    BiasReport entities per mandatory disclosure seguendo i principi del
    Constitutional Governance Model.

    Args:
        db: AsyncSession for database operations
        task_id: ID of the task to calculate bias for
        
    References:
        RLCF.md Section 4.3 - Extended Bias Detection Framework (6 dimensions)
        RLCF.md Section 5.1 - Constitutional Governance Model
    """
    try:
        # Get participants for this task
        result = await db.execute(
            select(models.User)
            .join(models.Feedback)
            .join(models.Response)
            .filter(models.Response.task_id == task_id)
            .distinct()
        )
        participants = result.scalars().all()

        for user in participants:
            bias_score = await bias_analysis.calculate_professional_clustering_bias(
                db, user.id, task_id
            )
            db_report = models.BiasReport(
                task_id=task_id,
                user_id=user.id,
                bias_type="PROFESSIONAL_CLUSTERING",
                bias_score=bias_score,
            )
            db.add(db_report)

        await db.commit()
    except Exception as e:
        print(f"Error in bias calculation for task {task_id}: {e}")
        await db.rollback()
