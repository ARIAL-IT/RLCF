task_types:
  SUMMARIZATION:
    input_data:
      document: str
    feedback_data:
      revised_summary: str
      rating: Literal["good", "bad"]
  CLASSIFICATION:
    input_data:
      text: str
      unit: str
    ground_truth_keys:
    - labels
    feedback_data:
      validated_labels: List[str]
      reasoning: str
  QA:
    input_data:
      context: str
      question: str
    ground_truth_keys:
    - answers
    feedback_data:
      validated_answer: str
      position: Literal["correct", "incorrect"]
      reasoning: str
  PREDICTION:
    input_data:
      facts: str
    ground_truth_keys:
    - outcome
    feedback_data:
      chosen_outcome: Literal["violation", "no_violation"]
      reasoning: str
  NLI:
    input_data:
      premise: str
      hypothesis: str
    feedback_data:
      chosen_label: Literal["entail", "contradict", "neutral"]
      reasoning: str
  NER:
    input_data:
      tokens: List[str]
    ground_truth_keys:
    - tags
    feedback_data:
      validated_tags: List[str]
      reasoning: str
  DRAFTING:
    input_data:
      source: str
      task: str
    ground_truth_keys:
    - target
    feedback_data:
      revised_target: str
      rating: Literal["better", "worse"]
      reasoning: str
  RISK_SPOTTING:
    input_data:
      text: str
    ground_truth_keys:
    - risk_labels
    - severity
    feedback_data:
      validated_risk_labels: List[str]
      validated_severity: int
      reasoning: str
  DOCTRINE_APPLICATION:
    input_data:
      facts: str
      question: str
    ground_truth_keys:
    - label
    - rationale
    feedback_data:
      chosen_label: Literal["yes", "no"]
      reasoning: str
